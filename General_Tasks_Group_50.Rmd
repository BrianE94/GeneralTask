---
title: "General_Tasks_Group_50"
author: "Long Dinh, Jonas Rieger, André Düding, Brian Eiffert, Vanessa Schweitzer"
date: "SoSe 2020, 31/07/2020"
output: html_document
  toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Data Preparation

### Step 1: Installing packages and loading libraries
```{r, message=FALSE, warning=FALSE}
install.packages("readr")
library(readr)

install.packages("dplyr")
library(dplyr)

install.packages("plotly")
library(plotly)
```

### Step 2: Import data 
All necessary CSV files are going to be imported. 
```{r, message=FALSE, warning=FALSE} 
komponente_k7 <- read_csv("Data/Logistikverzug/Komponente_K7.csv")
logistikverzug_k7 <- read_csv("Data/Logistikverzug/Logistics_delay_K7.csv")
```

### Step 3: Tidy data 
It is imperative to the data analytics process to fully understand the structure of the data in order to draw reliable and true conclusions from the data.   

```{r, message=FALSE, warning=FALSE}
head(komponente_k7)
head(logistikverzug_k7)
glimpse(komponente_k7)
glimpse(logistikverzug_k7)
summary(komponente_k7)
summary(logistikverzug_k7)
```

After further analysis, both data sets meet the three principles of tidy data: observations as rows, variables as columns and one type of observational unit per table.

# Task 1
Creation of new data set "Logistics delay" that contains the required information from both data sets to calculate the logistics delay between the receiving date of incoming goods and the production date.

```{r, message=FALSE}
logistics_delay <- inner_join(komponente_k7, logistikverzug_k7, by="IDNummer") %>%
  select(IDNummer, Produktionsdatum, Wareneingang) %>%
  mutate(Logistikverzug = as.numeric(difftime(Wareneingang, Produktionsdatum, units="days")))
```

### Subtask a
**How is the logistics delay distributed? Proof your selection by statistical tests and briefly describe your approach.**

### Subtask b
**What is the minimum/maximum time between delivering and receiving goods?**

### Subtask c
**Determine the mean of the logistics delay.**

### Subtask d
**Visualize the distribution in an appropriate way by displaying a histogram and the density function using the package plotly.**


# Task 2

**Why does it make sense to store the available data in separate files instead of saving everything in a huge table? Name at least four benefits. The available tables represent a typical data base structure. How is it called?**

The benefits are the reduction of the loading time of the imported data and the reduction of the high working memory consumption. It also avoids redundancy in big tables, as usually some values appear several times in the table/(spreadsheet). The searching time for exact figures/numbers in the table is therefore also reduced.

The typical data base structure is called relational database system. 

# Task 3

**How many of the parts T4 ended up in vehicles registered in the city of Dortmund?**

# Task 4

**Which data types do the attributes of the registration table "Zulassungen_aller_Fahrzeuge" have? Put your answers into a table which is integrated into your Markdown document.**

# Task 5

**You want to publish your application. Why does it make sense to store the data sets in a database on a server? Why is it not recommended to store the data sets on your personal computer? Name at least three points per question.**

# Task 6

**On 11 August 2019 there was an accident involving a stolen car produced by your company. The driver left the scene without a trace. The license plate of the car, which caused the accident, was faked and the Vehicle Identification Number (VIN) was removed. Since you work for the Federal Motor Transport Authority, the police asks for your help to find out where the vehicle with the engine code "K1DI2-103-1031-21" (corresponds to the engine ID number) was registered.**